{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating neural network from scratch with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference link for the code snippet- https://heartbeat.fritz.ai/building-a-neural-network-from-scratch-using-python-part-1-6d399df8d432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference link for the dataset - https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>serum_cholestoral</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_ecg_results</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope of the peak</th>\n",
       "      <th>num_of_major_vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;!DOCTYPE</td>\n",
       "      <td>html&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html</td>\n",
       "      <td>lang=\"en\"</td>\n",
       "      <td>data-color-mode=\"auto\"</td>\n",
       "      <td>data-light-theme=\"light\"</td>\n",
       "      <td>data-dark-theme=\"dark\"&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;head&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;meta</td>\n",
       "      <td>charset=\"utf-8\"&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;link</td>\n",
       "      <td>rel=\"dns-prefetch\"</td>\n",
       "      <td>href=\"https://github.githubassets.com\"&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        sex              chest_pain    resting_blood_pressure  \\\n",
       "0  <!DOCTYPE      html>                     NaN                       NaN   \n",
       "1      <html  lang=\"en\"  data-color-mode=\"auto\"  data-light-theme=\"light\"   \n",
       "2        NaN        NaN                  <head>                       NaN   \n",
       "3        NaN        NaN                     NaN                       NaN   \n",
       "4        NaN        NaN                   <link        rel=\"dns-prefetch\"   \n",
       "\n",
       "                         serum_cholestoral fasting_blood_sugar  \\\n",
       "0                                      NaN                 NaN   \n",
       "1                  data-dark-theme=\"dark\">                 NaN   \n",
       "2                                      NaN                 NaN   \n",
       "3                                    <meta    charset=\"utf-8\">   \n",
       "4  href=\"https://github.githubassets.com\">                 NaN   \n",
       "\n",
       "  resting_ecg_results max_heart_rate_achieved exercise_induced_angina oldpeak  \\\n",
       "0                 NaN                     NaN                     NaN     NaN   \n",
       "1                 NaN                     NaN                     NaN     NaN   \n",
       "2                 NaN                     NaN                     NaN     NaN   \n",
       "3                 NaN                     NaN                     NaN     NaN   \n",
       "4                 NaN                     NaN                     NaN     NaN   \n",
       "\n",
       "  slope of the peak num_of_major_vessels thal heart_disease  \n",
       "0               NaN                  NaN  NaN           NaN  \n",
       "1               NaN                  NaN  NaN           NaN  \n",
       "2               NaN                  NaN  NaN           NaN  \n",
       "3               NaN                  NaN  NaN           NaN  \n",
       "4               NaN                  NaN  NaN           NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Pandas module\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#Add header names\n",
    "headers =  ['age', 'sex','chest_pain','resting_blood_pressure',  \n",
    "        'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results',\n",
    "        'max_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak',\"slope of the peak\",\n",
    "        'num_of_major_vessels','thal', 'heart_disease']\n",
    "\n",
    "#Import dataset in the form of a dataframe\n",
    "heart_df = pd.read_csv('https://github.com/prateekef/workshopdata/blob/main/heart.dat', sep=' ', names=headers)\n",
    "\n",
    "#Looking at the first five rows of the dataset\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting shape of the data\n",
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for the null values through the dataset because neural net require non null variables\n",
    "heart_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing essential packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Splitting data into independant and depedant variables\n",
    "\n",
    "X = heart_df.drop(columns=['heart_disease']) #Independant data variables\n",
    "\n",
    "#replace target class with 0 and 1 \n",
    "#1 means \"have heart disease\" and 0 means \"do not have heart disease\"\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(1, 0)\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(2, 1)\n",
    "\n",
    "y_label = heart_df['heart_disease'].values.reshape(X.shape[0], 1) #Dependant or target variable\n",
    "\n",
    "#Split data into train and test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_label, test_size=0.2, random_state=2)\n",
    "\n",
    "#Standardize the dataset\n",
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)\n",
    "\n",
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet():\n",
    "    '''\n",
    "    A two layer neural network\n",
    "    '''\n",
    "        \n",
    "    def __init__(self, layers=[13,8,1], learning_rate=0.001, iterations=100):\n",
    "        self.params = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.loss = []\n",
    "        self.sample_size = None\n",
    "        self.layers = layers\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "                \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Initialize the weights from a random normal distribution\n",
    "        '''\n",
    "        np.random.seed(1) # Seed the random number generator\n",
    "        self.params[\"W1\"] = np.random.randn(self.layers[0], self.layers[1]) \n",
    "        self.params['b1']  =np.random.randn(self.layers[1],)\n",
    "        self.params['W2'] = np.random.randn(self.layers[1],self.layers[2]) \n",
    "        self.params['b2'] = np.random.randn(self.layers[2],)\n",
    "        \n",
    "    def relu(self,Z):\n",
    "        '''\n",
    "        The ReLu activation function is to performs a threshold\n",
    "        operation to each input element where values less \n",
    "        than zero are set to zero.\n",
    "        '''\n",
    "        return np.maximum(0,Z)\n",
    "    \n",
    "    def sigmoid(self,Z):\n",
    "        '''\n",
    "        The sigmoid function takes in real numbers in any range and \n",
    "        squashes it to a real-valued output between 0 and 1.\n",
    "        '''\n",
    "        return 1.0/(1.0+np.exp(-Z))\n",
    "    \n",
    "    def entropy_loss(self,y, yhat):\n",
    "        nsample = len(y)\n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat), y) + np.multiply((1 - y), np.log(1 - yhat))))\n",
    "        return loss\n",
    "    \n",
    "    def forward_propagation(self):\n",
    "        '''\n",
    "        Performs the forward propagation\n",
    "        '''\n",
    "        \n",
    "        Z1 = self.X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        yhat = self.sigmoid(Z2)\n",
    "        loss = self.entropy_loss(self.y,yhat)\n",
    "\n",
    "        # save calculated parameters     \n",
    "        self.params['Z1'] = Z1\n",
    "        self.params['Z2'] = Z2\n",
    "        self.params['A1'] = A1\n",
    "\n",
    "        return yhat,loss\n",
    "    \n",
    "    def back_propagation(self,yhat):\n",
    "        '''\n",
    "        Computes the derivatives and update weights and bias according.\n",
    "        '''\n",
    "        def dRelu(x):\n",
    "            x[x<=0] = 0\n",
    "            x[x>0] = 1\n",
    "            return x\n",
    "        \n",
    "        dl_wrt_yhat = -(np.divide(self.y,yhat) - np.divide((1 - self.y),(1-yhat)))\n",
    "        dl_wrt_sig = yhat * (1-yhat)\n",
    "        dl_wrt_z2 = dl_wrt_yhat * dl_wrt_sig\n",
    "\n",
    "        dl_wrt_A1 = dl_wrt_z2.dot(self.params['W2'].T)\n",
    "        dl_wrt_w2 = self.params['A1'].T.dot(dl_wrt_z2)\n",
    "        dl_wrt_b2 = np.sum(dl_wrt_z2, axis=0)\n",
    "\n",
    "        dl_wrt_z1 = dl_wrt_A1 * dRelu(self.params['Z1'])\n",
    "        dl_wrt_w1 = self.X.T.dot(dl_wrt_z1)\n",
    "        dl_wrt_b1 = np.sum(dl_wrt_z1, axis=0)\n",
    "        \n",
    "        #update the weights and bias\n",
    "        self.params['W1'] = self.params['W1'] - self.learning_rate * dl_wrt_w1\n",
    "        self.params['W2'] = self.params['W2'] - self.learning_rate * dl_wrt_w2\n",
    "        self.params['b1'] = self.params['b1'] - self.learning_rate * dl_wrt_b1\n",
    "        self.params['b2'] = self.params['b2'] - self.learning_rate * dl_wrt_b2\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Trains the neural network using the specified data and labels\n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.init_weights() #initialize weights and bias\n",
    "\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            yhat, loss = self.forward_propagation()\n",
    "            self.back_propagation(yhat)\n",
    "            self.loss.append(loss)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predicts on a test data\n",
    "        '''\n",
    "        Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        pred = self.sigmoid(Z2)\n",
    "        return np.round(pred) \n",
    "    \n",
    "    def acc(self, y, yhat):\n",
    "        '''\n",
    "        Calculates the accuracy between the predicted value and the truth labels\n",
    "        '''\n",
    "        acc = int(sum(y == yhat) / len(y) * 100)\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        Plots the loss curve\n",
    "        '''\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of class Neural net\n",
    "nn = NeuralNet(layers=[13,8,1], learning_rate=0.001, iterations=100) # create the NN model\n",
    "\n",
    "#Fit the train dataset to this object - training the model\n",
    "nn.fit(Xtrain, ytrain) #train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss \n",
    "nn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the train and test data \n",
    "train_pred = nn.predict(Xtrain)\n",
    "test_pred = nn.predict(Xtest)\n",
    "\n",
    "#Calculate the accuracy of the train and test datasets\n",
    "print(\"Train accuracy is {}\".format(nn.acc(ytrain, train_pred)))\n",
    "print(\"Test accuracy is {}\".format(nn.acc(ytest, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.loss[len(nn.loss)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating neural net with Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With help of Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With scikit learn - with multilayer perceptron classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sknet = MLPClassifier(hidden_layer_sizes=(8), learning_rate_init=0.001, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data to the classifier model\n",
    "sknet.fit(Xtrain, ytrain)\n",
    "preds_train = sknet.predict(Xtrain)\n",
    "preds_test = sknet.predict(Xtest)\n",
    "\n",
    "#Print the accuracy of the train and test datasets\n",
    "print(\"Train accuracy of sklearn neural network: {}\".format(round(accuracy_score(preds_train, ytrain),2)*100))\n",
    "print(\"Test accuracy of sklearn neural network: {}\".format(round(accuracy_score(preds_test, ytest),2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for how to save and load scikit learn model with pickle - https://www.geeksforgeeks.org/saving-a-machine-learning-model/#:~:text=There%20are%20two%20ways%20we,serializing%20a%20Python%20object%20structure.&text=pickle.,you%20simply%20use%20dump()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the help of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(8,input_shape=(13,)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model to data - Training \n",
    "model.fit(Xtrain, ytrain, epochs=100, verbose=1)\n",
    "\n",
    "#Calculate the train accuracy\n",
    "train_acc = model.evaluate(Xtrain, ytrain, verbose=1)[1]\n",
    "# print(train_acc)\n",
    "\n",
    "#Calculate the test accuracy\n",
    "test_acc = model.evaluate(Xtest, ytest, verbose=1)[1]\n",
    "# print(test_acc)\n",
    "\n",
    "print(\"Train accuracy of keras neural network: {}\".format(round((train_acc * 100), 2)))\n",
    "print(\"Test accuracy of keras neural network: {}\".format(round((test_acc * 100),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to save Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to save Keras models\n",
    "#save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to load the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to load saved keras model and use it again\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "#Load model\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "#Summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference link for how to save models and load them again - https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.predict(Xtest),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
